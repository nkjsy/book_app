{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25353, 2)\n",
      "                              title            author\n",
      "0                       The Martian         Andy Weir\n",
      "1  Career of Evil (Cormoran Strike)  Robert Galbraith\n",
      "2              The Crossing (Bosch)  Michael Connelly\n",
      "3           The Guilty (Will Robie)    David Baldacci\n",
      "4         Ready Player One: A Novel      Ernest Cline\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('book_list.csv',encoding = \"ISO-8859-1\", header=0)\n",
    "data.dropna(inplace=True)\n",
    "print (data.shape)\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n",
      "{'whereafter', 'be', 'afterwards', 'do', 'four', 'within', 'hundred', 'became', 'beside', 'yourself', 'anything', 'whole', 'empty', 'through', 'how', 'two', 'same', 'third', 'formerly', 'yours', 'should', 'we', 'anyhow', 'whenever', 'ltd', 'why', 'he', 'before', 'amount', 'been', 'or', 'enough', 'into', 'whereas', 'behind', 'had', 'latterly', 'full', 'get', 'only', 'five', 'this', 'still', 'was', 'others', 'else', 'whom', 'thereby', 'being', 'fill', 'eg', 'interest', 'myse\"', 'whoever', 'sometime', 'about', 'is', 'mostly', 'hence', 'hereby', 'fifteen', 'latter', 'under', 'up', 'anyway', 'along', 'many', 'them', 'thus', 'another', 'go', 'whither', 'since', 'where', 'becomes', 'hereupon', 'whether', 'thence', 'herse\"', 'by', 'hereafter', 'himse\"', 'but', 'the', 'against', 'it', 'towards', 'thereafter', 'she', 'ever', 'whatever', 'twenty', 'than', 'further', 'whereupon', 'must', 'to', 'upon', 'sincere', 'yourselves', 'am', 'seem', 'seeming', 'meanwhile', 'find', 'cannot', 'thereupon', 'also', 'then', 'very', 'anywhere', 'an', 'anyone', 'someone', 'indeed', 'as', 'put', 'have', 'due', 'found', 'perhaps', 'therefore', 'can', 'detail', 'eight', 'most', 'together', 'hasnt', 'fire', 'for', 'once', 'un', 'twelve', 'could', 'name', 'herein', 'first', 'has', 'wherever', 'off', 'beforehand', 'none', 'a', 'serious', 'namely', 'even', 'more', 'noone', 'hers', 'rather', 'least', 'last', 'on', 'some', 'amongst', 'these', 'mine', 'con', 'move', 'part', 'what', 'nowhere', 'eleven', 'thick', 'her', 'take', 'your', 'never', 'fify', 'at', 'now', 'they', 'beyond', 'co', 'throughout', 'too', 'thin', 'because', 'mill', 'already', 'here', 'otherwise', 'that', 'seemed', 'everything', 'though', 'cry', 'us', 'side', 'show', 'less', 'neither', 'may', 'out', 'thru', 'bill', 'from', 'will', 'both', 'when', 'during', 'not', 'nevertheless', 'nine', 'all', 'per', 'much', 'nobody', 'between', 'six', 'there', 'moreover', 'its', 'ourselves', 'therein', 'which', 'ours', 'elsewhere', 'above', 'becoming', 'forty', 'nothing', 'him', 'are', 'describe', 'everywhere', 'keep', 'please', 'me', 'such', 'so', 'always', 'although', 'alone', 'made', 'their', 'almost', 'somewhere', 'of', 'toward', 'after', 'each', 'among', 'couldnt', 'were', 'besides', 'either', 'my', 'several', 'every', 'former', 'system', 'ie', 'down', 'onto', 'yet', 'wherein', 'become', 'with', 'one', 'while', 'seems', 'sometimes', 'back', 'done', 'often', 'and', 'nor', 'i', 'without', 'however', 'themselves', 'call', 'computer', 'own', 'again', 'cant', 'over', 'whence', 'amoungst', 'bottom', 'other', 'in', 'few', 'top', 'via', 'below', 'those', 'our', 'sixty', 'give', 'whose', 'itse\"', 'you', 'inc', 'until', 'would', 'de', 'across', 'three', 're', 'around', 'next', 'no', 'if', 'see', 'except', 'front', 'somehow', 'might', 'something', 'any', 'everyone', 'who', 'etc', 'his', 'ten', 'well', 'whereby'}\n"
     ]
    }
   ],
   "source": [
    "sw_file = 'stopwords.txt'\n",
    "with open(sw_file, 'r') as fr:\n",
    "    stopwords = set(map(lambda x: x.strip(), fr.readlines()))\n",
    "print (len(stopwords))\n",
    "print (stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning\n",
    "\n",
    "### clean the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is english character?\n",
    "def is_valid(word):\n",
    "    for uchar in word:\n",
    "        if (uchar >= u'\\u0041' and uchar<=u'\\u005a') or (uchar >= u'\\u0061' and uchar<=u'\\u007a'):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to clean the title column\n",
    "punc = '[~`\\!\\#\\$\\%^\\&\\*\\'\\(\\)_\\+\\-\\=\\|\\[\\]\\\\/\\:;\\.,\\?\\>\\<\\@\\\"\\{\\}]'\n",
    "def clean_title(line):\n",
    "    result = []\n",
    "    # remove the punctuation\n",
    "    line = re.sub(re.compile(punc), '', line)\n",
    "    words = line.strip().split()\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        # exclude the stopwords or pure numbers\n",
    "        if word in stopwords or word.isdigit():\n",
    "            continue\n",
    "        # if not a valid english text, return a special text for future removal\n",
    "        if not is_valid(word):\n",
    "            return 'this is invalid'\n",
    "        result.append(word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_title = data['title'].map(clean_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the authors\n",
    "\n",
    "turn to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the author column\n",
    "def clean_author(line):\n",
    "    result = []\n",
    "    words = line.strip().split()\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        # if not a valid english text, return a special text for future removal\n",
    "        if not is_valid(word):\n",
    "            return 'this is invalid'\n",
    "        result.append(word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_author = data['author'].map(clean_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the lines with invalid text and duplicate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame({'title': col_title, 'author': col_author})\n",
    "clean_df = clean_df[clean_df['title'] != 'this is invalid']\n",
    "clean_df = clean_df[clean_df['author'] != 'this is invalid']\n",
    "clean_df = clean_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18416, 2)\n",
      "                         title            author\n",
      "0                      martian         andy weir\n",
      "1  career evil cormoran strike  robert galbraith\n",
      "2               crossing bosch  michael connelly\n",
      "3                 guilty robie    david baldacci\n",
      "4           ready player novel      ernest cline\n"
     ]
    }
   ],
   "source": [
    "print (clean_df.shape)\n",
    "print (clean_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>alice wonderland edition norton critical editions</td>\n",
       "      <td>lewis carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22454</th>\n",
       "      <td>alices adventures wonderland popup adaptation</td>\n",
       "      <td>lewis carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         author\n",
       "4788   alice wonderland edition norton critical editions  lewis carroll\n",
       "22454      alices adventures wonderland popup adaptation  lewis carroll"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['author'] == 'lewis carroll']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate the title and author together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = pd.DataFrame(clean_df['title'] + ' ' + clean_df['author'], columns=['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>martian andy weir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>career evil cormoran strike robert galbraith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crossing bosch michael connelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guilty robie david baldacci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ready player novel ernest cline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            all\n",
       "0                             martian andy weir\n",
       "1  career evil cormoran strike robert galbraith\n",
       "2               crossing bosch michael connelly\n",
       "3                   guilty robie david baldacci\n",
       "4               ready player novel ernest cline"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df.to_csv('clean.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vectorize the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJ\\Anaconda3\\envs\\ml1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1817: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. float32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18416, 5000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3, max_features=5000, analyzer='word', token_pattern=r'\\w+', use_idf=True, smooth_idf=True, dtype='float32')\n",
    "vectors = vectorizer.fit_transform(one_df['all'])\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF vectorizer saved\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(vectorizer, '../model/vectorizer.pkl')\n",
    "print (\"TFIDF vectorizer saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18416, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, learning_method='online')\n",
    "vectors_topic = lda.fit_transform(vectors)\n",
    "vectors_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA model saved\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(lda, '../model/lda.pkl')\n",
    "print (\"LDA model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# books clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Mixture Model saved\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=8, max_iter=100, random_state=2020)\n",
    "gmm.fit(vectors_topic)\n",
    "joblib.dump(gmm, '../model/gmm.pkl')\n",
    "print (\"Gaussian Mixture Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = gmm.predict_proba(vectors_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.96475978e-01,\n",
       "       6.79285763e-08, 0.00000000e+00, 3.52395430e-03, 0.00000000e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[45,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
